from langchain_community.chat_models.ollama import ChatOllama

llm = ChatOllama(model="phi3:3.8b-mini-128k-instruct-q4_K_S")
